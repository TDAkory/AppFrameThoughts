# [Prefix Code](https://en.wikipedia.org/wiki/Prefix_code)

Prefix codes / Prefix-free codes / Instantaneous codes:

No codeword is a prefix of another codeword.

## 核心原理一：概率与码长的对应关系

如果符号 s_1 的概率 \(P(s_1) > P(s_2)\)，则其码长应满足：

\[l(s_1) \leq l(s_2)\]

即概率越大的符号，编码长度应越短。

解释：  
这是构建最优前缀码（如霍夫曼编码）的基本原则。通过将较短的码字分配给高频符号，可以最小化平均码长 \(E[l(x)]\)。如果违反此规则，可以通过交换两符号的码字来获得更短的平均码长。

## 核心原理二：最优码长的近似公式

理想情况下，单个符号的最优码长近似为：

\[l(x) \approx \log_2 \frac{1}{P(x)}\]

解释：  
该公式来源于香农信息论，表示符号 x 的最优码长应接近其“信息量”或“自信息” \(-\log_2 P(x)\)。

• 当 \(P(x) = 1\)（必然出现），\(l(x) \approx 0\)，无需编码。  

• 当 \(P(x) = 0.5\)，\(l(x) \approx 1\) 比特。  

• 当 \(P(x)\) 很小，\(l(x)\) 很大，因为罕见符号应使用较长码字。

注意：实际编码（如霍夫曼编码）的码长必须是整数，因此只能近似该理论值。

总结与应用

这两条原理共同指导如何设计最小化平均码长的前缀码：

1. 排序分配：将符号按概率降序排列，概率越大码长越短。
2. 码长目标：使每个符号的码长尽量接近 \(-\log_2 P(x)\)。
3. 优化方法：霍夫曼编码、香农-法诺编码等算法是这些原理的具体实现。

公式推导提示：  
最小化平均码长 \(E[l(X)] = \sum P(x) l(x)\)，在满足 Kraft 不等式 \(\sum 2^{-l(x)} \leq 1\) 的条件下，用拉格朗日乘子法可推导出 \(l(x) = -\log_2 P(x)\) 为理论最优解。

## 香农编码

香农编码是信息论中一种重要的**变长编码方法**，它的核心思想很直观：**为出现概率大的符号分配短的码字，为出现概率小的符号分配长的码字**，从而在整体上降低平均码长，实现高效的数据压缩。

下表清晰地展示了香农编码与其他两种常见变长编码方法的关键特性对比：

| 编码方法 | 提出者与时间 | 是否最佳码 | 核心原理 | 优点 | 缺点 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **香农编码** | 克劳德·香农 (1948) | **否** (除特定情况) | 基于符号的**累计概率** | 理论奠基，算法简单直观 | 平均码长通常非最短，效率不高 |
| **费诺编码** | 罗伯特·费诺 (1949) | **否** | **递归二分**信源，使分组概率和近似相等 | 编码效率通常优于香农编码 | 结果不唯一，受分组策略影响，可能非最优 |
| **霍夫曼编码** | 戴维·霍夫曼 (1952) | **是** (对多元独立信源) | **自底向上**构建二叉树，合并概率最小的符号 | **平均码长最短**，是最佳码 | 编码复杂度高于香农编码和费诺编码 |

### 🔢 编码步骤详解

香农编码的步骤非常规整，下面我们结合一个例子来具体说明。假设有一个信源，包含6个符号A、B、C、D、E、F，其出现概率分别为：`[0.25, 0.25, 0.2, 0.15, 0.10, 0.05]`。

1.  **排序信源符号**：首先，将信源符号按照其出现的概率从大到小进行降序排列。
    | 符号 | 概率 |
    | :--- | :--- |
    | A | 0.25 |
    | B | 0.25 |
    | C | 0.20 |
    | D | 0.15 |
    | E | 0.10 |
    | F | 0.05 |

2.  **计算码字长度**：对于每个符号，根据公式 \( l_i = \lceil -\log_2(p_i) \rceil \) 计算其码字长度，其中 \( p_i \) 是符号概率，\( \lceil \cdot \rceil \) 表示向上取整。这个公式确保码长能唯一表示该符号的信息量。
    | 符号 | 概率 | \( -\log_2(p_i) \) | 计算过程（取整） | 码长 \( l_i \) |
    | :--- | :--- | :--- | :--- | :--- |
    | A | 0.25 | \( -\log_2(0.25) = 2 \) | \( \lceil 2 \rceil \) | 2 |
    | B | 0.25 | \( -\log_2(0.25) = 2 \) | \( \lceil 2 \rceil \) | 2 |
    | C | 0.20 | \( -\log_2(0.20) \approx 2.32 \) | \( \lceil 2.32 \rceil = 3 \) | 3 |
    | D | 0.15 | \( -\log_2(0.15) \approx 2.74 \) | \( \lceil 2.74 \rceil = 3 \) | 3 |
    | E | 0.10 | \( -\log_2(0.10) \approx 3.32 \) | \( \lceil 3.32 \rceil = 4 \) | 4 |
    | F | 0.05 | \( -\log_2(0.05) \approx 4.32 \) | \( \lceil 4.32 \rceil = 5 \) | 5 |

3.  **计算累加概率**：计算每个符号的累加概率（也称累积概率）\( P_i \)。第一个符号的累加概率为0，后续符号的累加概率等于它前面所有符号的概率之和。
    | 符号 | 概率 | 累加概率 \( P_i \) |
    | :--- | :--- | :--- |
    | A | 0.25 | 0.00 |
    | B | 0.25 | 0.25 (A的概率) |
    | C | 0.20 | 0.50 (A+B的概率) |
    | D | 0.15 | 0.70 (A+B+C的概率) |
    | E | 0.10 | 0.85 (A+B+C+D的概率) |
    | F | 0.05 | 0.95 (A+B+C+D+E的概率) |

4.  **将累加概率转换为二进制码字**：将每个符号的累加概率 \( P_i \) 转换为二进制小数，然后取该二进制小数的小数点后前 \( l_i \) 位（即码长位）作为该符号的最终码字。
    | 符号 | 概率 | 码长 \( l_i \) | 累加概率 \( P_i \) | \( P_i \) (二进制) | 取前 \( l_i \) 位作为码字 |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | A | 0.25 | 2 | 0.00 | 0.00 | **00** |
    | B | 0.25 | 2 | 0.25 | 0.01 | **01** |
    | C | 0.20 | 3 | 0.50 | 0.100 | **100** |
    | D | 0.15 | 3 | 0.70 | 0.1011001... | **101** |
    | E | 0.10 | 4 | 0.85 | 0.110110011... | **1101** |
    | F | 0.05 | 5 | 0.95 | 0.111100111... | **11110** |

    最终，我们得到所有符号的香农码字。

### 💡 核心原理与评价

- **理论基础**：香农编码的理论基础是香农第一定理（可变长无失真信源编码定理）。该定理指出，在对信源符号进行编码时，每个符号的平均码长其极限值就是信源的**熵** (Entropy)。香农编码是这一理论最直接的体现。
- **即时码**：香农编码产生的码是**即时码**（也称前缀码），即任何一个码字都不是另一个码字的前缀。这使得在解码时，一旦识别出一个完整的码字，就可以立即翻译它，无需等待后续码字，解码非常高效且无歧义。
- **编码效率**：虽然香农编码在理论上有重要的指导意义，但在实际应用中，其**编码效率通常不是最高的**，即它的平均码长一般**不是最短的**。相比之下，霍夫曼编码通常能获得更短的平均码长，是更优的实用选择。

## Kraft不等式

Kraft不等式是信息论和编码理论中一个**基础且重要的数学关系**，它为特定码字长度集合能否构成某类有效编码提供了判断准则。下表概括了其核心要点与应用。

| 特性维度 | 核心描述 |
| :--- | :--- |
| **基本形式** | 对于 D 元字母表，若一组码字长度为 $l_1, l_2, ..., l_m$，则存在对应前缀码的**充要条件**是满足 $\sum_{k=1}^{m} D^{-l_k} \leq 1$。 |
| **适用范围** | 该不等式最初针对**前缀码**（即时码）提出，但麦克米兰证明它也适用于所有**唯一可译码**。这意味着，唯一可译码的码长也必须满足此不等式。 |
| **不等式状态** | **和小于1**：编码存在**冗余**。<br>**和等于1**：编码是**完备码**，所有可能的码字组合都被使用，没有浪费。<br>**和大于1**：**不可能**构造出唯一可译码。 |
| **核心价值** | 它建立了码字长度与编码存在性之间的桥梁，是判断能否构造出特定编码的**理论基石**。 |

### 🔢 直观理解：D叉树模型

理解Kraft不等式最直观的方式是借助**D叉树**的比喻。
-   想象一棵树，每个节点最多有 **D 个子分支**（对应D元字母表，如二进制D=2）。
-   树的**根节点**位于第0层。
-   一个长度为 $l_i$ 的码字，可以看作是从根节点出发，沿着树枝走 $l_i$ 步后到达的一个**叶子节点**。
-   **前缀码的关键规则**是：**任何一个码字对应的节点，都不能是另一个更长码字的祖先节点**。也就是说，一旦某个节点被选为码字，它的所有后代节点就都不能再被用作其他码字了。

在这个模型下，一个长度为 $l_i$ 的码字，实际上"独占"了以它为根的一棵子树，这棵子树在最深层（假设最大码长为 $l_{max}$）拥有 $D^{l_{max} - l_i}$ 个叶子节点。所有码字所"独占"的叶子节点总数，不能超过整棵树在最深层所能拥有的叶子节点总数 $D^{l_{max}}$。将不等式两边同时除以 $D^{l_{max}}$，就得到了Kraft不等式 $\sum D^{-l_i} \leq 1$。这就像是在说，所有码字分占的"地盘"总和不能超过整个"星球"的面积。

### 💡 主要应用场景
1.  **判断编码的存在性**：这是Kraft不等式最直接的应用。在设计变长编码（如霍夫曼编码）时，在确定码长后，可以先用Kraft不等式验证是否存在对应的前缀码。如果不满足不等式，则需调整码长。
2.  **评估编码效率**：不等式求和的结果（冗余度）可以衡量编码的紧凑程度。当求和等于1时（完备码），意味着编码空间被完全利用，没有冗余，效率最高。
3.  **关联最优码长**：在寻找平均码长最短的最优编码时，Kraft不等式常作为约束条件出现在优化问题中。理论上，最优码长 $l_i^*$ 与符号概率 $p_i$ 的理想关系是 $l_i^* = -\log_D p_i$，此时平均码长等于信源的熵 $H_D(X)$，达到了理论下限。
